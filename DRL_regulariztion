# -*- coding: utf-8 -*-
"""
Full analysis script for Dynamical Reaction Landscape (DRL) and
Minimum Action Path (MAP) calculation from RACIPE output.

This version is a complete and stable implementation, faithfully reproducing
the logic of the reference MATLAB code and foundational papers. It includes
a symmetry-breaking initial path to ensure robust convergence.
"""
import os
import numpy as np
import pandas as pd
import string
import matplotlib.pyplot as plt
from scipy.linalg import eigh, solve_continuous_lyapunov
from scipy.stats import multivariate_normal
from sympy import symbols, Matrix, lambdify, pprint
from scipy.optimize import minimize, root, Bounds
from scipy.interpolate import interp1d
from scipy.ndimage import map_coordinates

# --- Actual Data Loading ---
try:
    from make_sense_of_RACIPE import steady_states, parameter_set
    from polisher import polish_racipe_dataframe
except ImportError as e:
    print(f"FATAL ERROR: Could not import a required module: {e}")
    print("Please ensure 'make_sense_of_RACIPE.py' and 'state_polisher.py' are in your Python path.")
    exit()

# --- Helper Functions ---

def _action_S_regularized(phi_flat, time_mesh, M_dims, f_drift, phi_start, phi_end, regularization_lambda):
    """
    Calculates the action with an added Tikhonov regularization term (smoothness penalty)
    to punish paths with high acceleration (sharp turns).
    """
    phi_internal = phi_flat.reshape((M_dims, -1))
    full_path = np.column_stack((phi_start, phi_internal, phi_end))
    delta_ts = np.diff(time_mesh)
    
    # --- 1. Standard Action Calculation ---
    phir = full_path[:, 1:]
    phil = full_path[:, :-1]
    phihalf = (phir + phil) / 2.0
    d_phi_dt = (phir - phil) / (delta_ts + 1e-12)
    f_at_phihalf = f_drift(phihalf)
    integrand = np.sum((d_phi_dt - f_at_phihalf)**2, axis=0)
    action_original = 0.5 * np.sum(integrand * delta_ts)

    # --- 2. Smoothness Regularization Penalty ---
    if regularization_lambda > 0:
        accel = np.diff(d_phi_dt, axis=1)
        accel_sq_mag = np.sum(accel**2, axis=0)
        dt_for_accel = (delta_ts[:-1] + delta_ts[1:]) / 2.0
        smoothness_penalty = 0.5 * np.sum(accel_sq_mag * dt_for_accel)
        return action_original + regularization_lambda * smoothness_penalty
    
    return action_original

def _monitor_function(path, time_mesh, c):
    phir = path[:, 1:]
    phil = path[:, :-1]
    delta_ts = np.diff(time_mesh)
    velocity = (phir - phil) / (delta_ts + 1e-12)
    velocity_sq_mag = np.sum(velocity**2, axis=0)
    w = np.sqrt(1.0 + c * velocity_sq_mag)
    return w

def remesh_path_and_time(old_phi, old_time_mesh, n_points, c):
    monitor = _monitor_function(old_phi, old_time_mesh, c)
    delta_ts_old = np.diff(old_time_mesh)
    alpha = np.zeros(len(old_time_mesh))
    alpha[1:] = np.cumsum(monitor * delta_ts_old)
    if alpha[-1] > 0: alpha /= alpha[-1]
    unique_indices = np.unique(alpha, return_index=True)[1]
    alpha_unique, old_time_mesh_unique, old_phi_unique = alpha[unique_indices], old_time_mesh[unique_indices], old_phi[:, unique_indices]
    path_interp_kind = 'cubic' if len(unique_indices) >= 4 else 'linear'
    alpha_new = np.linspace(0, 1, n_points)
    time_mesh_new = interp1d(alpha_unique, old_time_mesh_unique, kind='linear', fill_value="extrapolate")(alpha_new)
    phi_new_T = interp1d(alpha_unique, old_phi_unique.T, kind=path_interp_kind, axis=0, fill_value="extrapolate")(alpha_new)
    return phi_new_T.T, time_mesh_new

def _action_cost(path, time_mesh, drift_func, regularization_lambda=0.0):
    M_dims = path.shape[1]
    phi_start = path[0]
    phi_end = path[-1]
    # Transpose path to (M_dims, N) for internal calculations
    phi_internal_flat = path.T[:, 1:-1].flatten()
    return _action_S_regularized(phi_internal_flat, time_mesh, M_dims, drift_func, phi_start, phi_end, regularization_lambda)

def aMAM_advanced_solver(f_drift, x0, x1, N, T_max, k_max, c, qmin=5.0, 
                         phi_init=None, initial_path='linear', 
                         # --- START OF MODIFICATION 1: Add regularization_lambda parameter ---
                         regularization_lambda=0.0):
    """
    aMAM solver with flexible initial path and path regularization.
    """
    M_dims = len(x0)
    
    # Initial path generation
    if phi_init is not None:
        phi = phi_init.T
    elif initial_path == 'log':
        x0_log, x1_log = np.log(np.maximum(x0, 1e-12)), np.log(np.maximum(x1, 1e-12))
        path_init_log = np.array([np.linspace(s, e, N) for s, e in zip(x0_log, x1_log)]).T
        phi = np.exp(path_init_log).T
    else: # Default to linear
        path_init_T = np.array([np.linspace(s, e, N) for s, e in zip(x0, x1)]).T
        phi = path_init_T.T

    time_mesh = np.linspace(-T_max / 2.0, T_max / 2.0, N)
    num_internal_points = N - 2
    
    optimizer_options = {'maxiter': 300, 'disp': False, 'ftol': 1e-15, 'gtol': 1e-8, 'maxcor': 10}

    for k in range(k_max):
        print(f"\n--- aMAM Remeshing Cycle {k+1}/{k_max} ---")
        
        # --- START OF MODIFICATION 2: Use the regularized action function ---
        objective_func = lambda p: _action_S_regularized(p, time_mesh, M_dims, f_drift, x0, x1, regularization_lambda)
        
        phi_internal_flat = phi[:, 1:-1].flatten()
        result = minimize(objective_func, phi_internal_flat, method='L-BFGS-B', options=optimizer_options)
        
        phi_optimized_internal = result.x.reshape((M_dims, num_internal_points))
        phi_optimized = np.column_stack((x0, phi_optimized_internal, x1))
        
        w = _monitor_function(phi_optimized, time_mesh, c)
        delta_ts = np.diff(time_mesh)
        wdelt = w * delta_ts
        q = np.max(wdelt) / np.min(wdelt) if np.min(wdelt) > 0 else float('inf')
        
        print(f"Mesh quality q = {q:.2f}")
        
        if q > qmin and k < k_max - 1:
            phi, time_mesh = remesh_path_and_time(phi_optimized, time_mesh, N, c)
        else:
            phi = phi_optimized
            print("Convergence criterion met or final iteration. Halting remeshing.")
            break

    print("--- aMAM solver finished ---")
    return phi.T, time_mesh


def _generate_odes(adjacency_matrix, gene_symbols, params_row):
    odes = []
    for i in range(len(gene_symbols)):
        regulated_gene = gene_symbols[i]
        production_term = float(params_row.get(f'Prod_of_{regulated_gene.name}', 50.0))
        k_deg = float(params_row.get(f'Deg_of_{regulated_gene.name}', 1.0))
        degradation_term = k_deg * regulated_gene
        regulation_product = 1
        for j in range(len(gene_symbols)):
            regulation_type = adjacency_matrix[i][j]
            if regulation_type != 0:
                regulator_gene = gene_symbols[j]
                param_prefix = f'of_{regulator_gene.name}To{regulated_gene.name}'
                s = float(params_row.get(f'Trd_{param_prefix}', 16.0))
                n = float(params_row.get(f'Num_{param_prefix}', 4.0))
                if regulation_type > 0:
                    l = float(params_row.get(f'Act_{param_prefix}', 10.0))
                    numerator = l + (1.0 - l) * (s**n / (regulator_gene**n + s**n))
                    regulation_product *= numerator / l
                elif regulation_type < 0:
                    l = float(params_row.get(f'Inh_{param_prefix}', 0.1))
                    reg_strength = s**n / (regulator_gene**n + s**n)
                    regulation_product *= l + (1.0 - l) * reg_strength
        ode = production_term * regulation_product - degradation_term
        odes.append(ode)
    return odes

def _calculate_jacobian(system_odes, variables, steady_state_vector):
    sub_dict = {var: steady_state_vector[i] for i, var in enumerate(variables)}
    gen_matrix = Matrix(system_odes)
    jac_matrix = gen_matrix.jacobian(variables)
    return np.array(jac_matrix.subs(sub_dict)).astype(np.float64)

def _solve_lyapunov(jacobian_matrix, d=0.1):
    Q = -2 * d * np.eye(len(jacobian_matrix))
    try: return solve_continuous_lyapunov(jacobian_matrix, Q)
    except np.linalg.LinAlgError: return np.zeros_like(jacobian_matrix)

def _global_covariance_matrix(ss_vectors_linear, ss_freqs, dims, odes, symbols, d):
    local_cov, stable_vec, stable_freq = [], [], []
    for i, vec in enumerate(ss_vectors_linear):
        jac = _calculate_jacobian(odes, symbols, vec)
        eigvals, _ = np.linalg.eig(jac)
        if np.all(np.real(eigvals) < -1e-9):
            stable_vec.append(vec); stable_freq.append(ss_freqs[i]); local_cov.append(_solve_lyapunov(jac, d=d))
    if len(stable_vec) < 2: return None, None, None, None
    stable_freq = np.array(stable_freq) / np.sum(stable_freq)
    mu_g = np.sum(stable_freq[:, np.newaxis] * stable_vec, axis=0)
    sigma_g = np.zeros((dims, dims))
    for i in range(len(stable_vec)):
        mean_diff = stable_vec[i] - mu_g
        sigma_g += stable_freq[i] * (local_cov[i] + np.outer(mean_diff, mean_diff))
    return sigma_g, local_cov, stable_vec, stable_freq

def _pca_analysis(global_cov_matrix):
    eigevals, eigenvectors = eigh(global_cov_matrix)
    sorted_indices = np.argsort(eigevals)[::-1]
    return eigenvectors[:, sorted_indices[0]], eigenvectors[:, sorted_indices[1]], eigevals[sorted_indices] / np.sum(eigevals)

def _project_vectors(vectors, transformation_matrix):
    return [transformation_matrix.T @ vec for vec in vectors]

def _generate_drift_function(system_odes, gene_symbols):
    f_numeric = lambdify(tuple(gene_symbols), system_odes, modules="numpy")
    return lambda x: np.array(f_numeric(*x), dtype=np.float64)

def visualize_landscape(U, X_grid, Y_grid, projected_ss, saddle_coords_ab, proj_path_ab, saddle_coords_ba, proj_path_ba):
    """
    Standard visualization function without outlier masking for paths.
    """
    plt.figure(figsize=(10, 8))
    vmax_clip = np.percentile(U, 99)
    x_min_plot, x_max_plot = X_grid.min(), X_grid.max()
    y_min_plot, y_max_plot = Y_grid.min(), Y_grid.max()

    contour = plt.contourf(X_grid, Y_grid, U, levels=100, cmap='viridis_r', vmax=vmax_clip)
    plt.colorbar(contour, label='Potential Energy (U = -ln(P))')

    # Plot stable states
    if projected_ss:
        plt.plot(projected_ss[0][0], projected_ss[0][1], 'o', color='white', markeredgecolor='black', markersize=8, label='Stable State A')
        if len(projected_ss) > 1:
            plt.plot(projected_ss[1][0], projected_ss[1][1], 's', color='cyan', markeredgecolor='black', markersize=8, label='Stable State B')

    # Plot saddle points
    if saddle_coords_ab is not None:
        plt.plot(saddle_coords_ab[0], saddle_coords_ab[1], 'X', color='red', markersize=9, markeredgecolor='white', label='Saddle Point(s)', zorder=5)
    if saddle_coords_ba is not None and (saddle_coords_ab is None or not np.allclose(saddle_coords_ab, saddle_coords_ba)):
        plt.plot(saddle_coords_ba[0], saddle_coords_ba[1], 'X', color='red', markersize=9, markeredgecolor='white', zorder=5)

    # Plot the raw projected paths directly
    if proj_path_ab is not None:
        path_array_ab = np.array(proj_path_ab)
        plt.plot(path_array_ab[:, 0], path_array_ab[:, 1], 'w--', linewidth=1.5, label='Path A -> B', zorder=4)
    if proj_path_ba is not None:
        path_array_ba = np.array(proj_path_ba)
        plt.plot(path_array_ba[:, 0], path_array_ba[:, 1], 'm:', linewidth=2.0, label='Path B -> A', zorder=4)

    plt.title('Potential Energy Landscape with Transition Paths', fontsize=16)
    plt.xlabel('Principal Component 1', fontsize=12)
    plt.ylabel('Principal Component 2', fontsize=12)
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.5)
    # Set plot limits to the landscape boundaries to maintain a consistent view
    plt.xlim(x_min_plot, x_max_plot)
    plt.ylim(y_min_plot, y_max_plot)
    plt.gca().set_aspect('equal', 'box')
    plt.show()


# --- MAIN ANALYSIS FUNCTION ---
def run_drl_analysis(network_name, adjacency_matrix, param_id, d_coefficient=0.1, grid_resolution=200, padding_factor=1.2, 
                     visualize=False,
                     N_points=100, T_max=120.0, k_steps=50, c_param=1e10,
                     # --- START OF MODIFICATION 3: Add new parameter to the main function call ---
                     regularization_lambda=0.0):
    
    # ... (Setup and data loading logic remains the same) ...
    num_dims = len(adjacency_matrix)
    node_list = [list(string.ascii_uppercase)[i] for i in range(num_dims)]
    full_ss_df = steady_states(network_name, node_list)
    racipe_df_subset = full_ss_df[full_ss_df['PS.No'] == param_id]
    if racipe_df_subset.empty: print("Param ID not found."); return None
    network_params = parameter_set(network_name).loc[param_id]
    polished_df, _ = polish_racipe_dataframe(racipe_df_subset, adjacency_matrix, network_params, node_list)
    polished_ss_vectors = [2**np.array(row[node_list].values) for _, row in polished_df.iterrows()]
    polished_freqs = polished_df['Freq'].values / np.sum(polished_df['Freq'].values)
    gene_symbols = symbols(node_list)
    system_odes = _generate_odes(adjacency_matrix, gene_symbols, network_params)
    sigma_global, local_sigmas, stable_vectors, stable_freqs = _global_covariance_matrix(
        polished_ss_vectors, polished_freqs, num_dims, system_odes, gene_symbols, d_coefficient)
    if sigma_global is None: return None
    pc1, pc2, _ = _pca_analysis(sigma_global)
    V = np.column_stack((pc1, pc2))

    log_stable_vectors = [np.log2(np.maximum(vec, 1e-12)) for vec in stable_vectors]
    projected_ss = _project_vectors(log_stable_vectors, V)
    print("Projected Steady States: ", projected_ss)

    proj_array = np.array(projected_ss)
    center = proj_array.mean(axis=0)
    max_dist = np.max(np.linalg.norm(proj_array - center, axis=1)) if proj_array.size > 0 else 1.0
    grid_width = max_dist * 2 * padding_factor
    
    x_min, x_max = center[0] - grid_width, center[0] + grid_width
    y_min, y_max = center[1] - grid_width, center[1] + grid_width
    
    # --- 2. CONSTRUCT THE ENERGY LANDSCAPE U(x) ---
    X_grid, Y_grid = np.meshgrid(np.linspace(x_min, x_max, grid_resolution), np.linspace(y_min, y_max, grid_resolution))
    pos = np.dstack((X_grid, Y_grid))
    
    P = np.zeros_like(X_grid)
    for i in range(len(projected_ss)):
        proj_cov = V.T @ local_sigmas[i] @ V
        P += stable_freqs[i] * multivariate_normal(mean=projected_ss[i], cov=proj_cov).pdf(pos)
        
    U = -np.log(np.maximum(P, 1e-100))
    print("Potential energy landscape constructed.")

    if len(stable_vectors) != 2:
        print("This analysis requires exactly two stable states.")
        return None

    drift_function = _generate_drift_function(system_odes, gene_symbols)
    
    # Bundle solver arguments into a dictionary
    solver_args = {'N': N_points, 'T_max': T_max, 'k_max': k_steps, 'c': c_param,
                   # --- START OF MODIFICATION 4: Pass lambda to the solver ---
                   'regularization_lambda': regularization_lambda}

    print("\nCalculating path from State A to State B...")
    map_a_to_b, time_mesh_ab = aMAM_advanced_solver(drift_function, stable_vectors[0], stable_vectors[1], **solver_args)
    print("\nCalculating path from State B to State A...")
    map_b_to_a, time_mesh_ba = aMAM_advanced_solver(drift_function, stable_vectors[1], stable_vectors[0], **solver_args)
    def plot_path_diagnostics(map_a_to_b, time_mesh_ab, map_b_to_a, time_mesh_ba, var_names=['A', 'B','C','D']):
        fig, ax = plt.subplots(2, 2, figsize=(6,6))
        fig.suptitle('Minimum Action Path Diagnostic Plots', fontsize=16)
        x_ab, y_ab = map_a_to_b[:, 0], map_a_to_b[:, 1]
        ax[0, 0].plot(time_mesh_ab, x_ab, label=f'Concentration of {var_names[0]}')
        ax[0, 0].plot(time_mesh_ab, y_ab, label=f'Concentration of {var_names[1]}')
        ax[0, 0].set_title('Time Series Trajectory (A to B)')
        ax[0, 0].set_xlabel('Time (from solver)')
        ax[0, 0].set_ylabel('Concentration')
        ax[0, 0].legend()
        ax[0, 0].grid(True, linestyle='--', alpha=0.5)
        ax[0, 1].plot(x_ab, y_ab, 'b-')
        ax[0, 1].plot(x_ab[0], y_ab[0], 'o', c='cyan', mec='black', ms=8, label='Start (State A)')
        ax[0, 1].plot(x_ab[1], y_ab[1], 's', c='white', mec='black', ms=8, label='End (State B)')
        ax[0, 1].set_title('Phase Portrait (A to B)')
        ax[0, 1].set_xlabel(f'Concentration of {var_names[0]}')
        ax[0, 1].set_ylabel(f'Concentration of {var_names[1]}')
        ax[0, 1].legend()
        ax[0, 1].grid(True, linestyle='--', alpha=0.5)
        x_ba, y_ba = map_b_to_a[:, 0], map_b_to_a[:, 1]
        ax[1, 0].plot(time_mesh_ba, x_ba, label=f'Concentration of {var_names[0]}')
        ax[1, 0].plot(time_mesh_ba, y_ba, label=f'Concentration of {var_names[1]}')
        ax[1, 0].set_title('Time Series Trajectory (B to A)')
        ax[1, 0].set_xlabel('Time (from solver)')
        ax[1, 0].set_ylabel('Concentration')
        ax[1, 0].legend()
        ax[1, 0].grid(True, linestyle='--', alpha=0.5)
        ax[1, 1].plot(x_ba, y_ba, 'm:')
        ax[1, 1].plot(x_ba[0], y_ba[0], 's', c='white', mec='black', ms=8, label='Start (State B)')
        ax[1, 1].plot(x_ba[-1], y_ba[-1], 'o', c='cyan', mec='black', ms=8, label='End (State A)')
        ax[1, 1].set_title('Phase Portrait (B to A)')
        ax[1, 1].set_xlabel(f'Concentration of {var_names[0]}')
        ax[1, 1].set_ylabel(f'Concentration of {var_names[1]}')
        ax[1, 1].legend()
        ax[1, 1].grid(True, linestyle='--', alpha=0.5)
        plt.tight_layout(rect=[0, 0, 1, 0.96])
        plt.show()
    plot_path_diagnostics(map_a_to_b, time_mesh_ab, map_b_to_a, time_mesh_ba)

    action_a_to_b = _action_cost(map_a_to_b, time_mesh_ab, drift_function)
    action_b_to_a = _action_cost(map_b_to_a, time_mesh_ba, drift_function)
    
    proj_path_ab = _project_vectors([np.log2(np.maximum(p, 1e-12)) for p in map_a_to_b], V)
    proj_path_ba = _project_vectors([np.log2(np.maximum(p, 1e-12)) for p in map_b_to_a], V)
    
    path_grid_indices_ab = (np.array([(np.abs(Y_grid[:, 0] - p[1])).argmin() for p in proj_path_ab]), np.array([(np.abs(X_grid[0, :] - p[0])).argmin() for p in proj_path_ab]))
    path_U_values_ab = U[path_grid_indices_ab]
    path_grid_indices_ba = (np.array([(np.abs(Y_grid[:, 0] - p[1])).argmin() for p in proj_path_ba]), np.array([(np.abs(X_grid[0, :] - p[0])).argmin() for p in proj_path_ba]))
    path_U_values_ba = U[path_grid_indices_ba]

    saddle_idx_ab, U_saddle_ab = np.argmax(path_U_values_ab), np.max(path_U_values_ab)
    saddle_coords_ab = proj_path_ab[saddle_idx_ab]
    saddle_idx_ba, U_saddle_ba = np.argmax(path_U_values_ba), np.max(path_U_values_ba)
    saddle_coords_ba = proj_path_ba[saddle_idx_ba]
    U_stable_A = path_U_values_ab[0]
    U_stable_B = path_U_values_ba[0] 
    barrier_height_ab = U_saddle_ab - U_stable_A
    barrier_height_ba = U_saddle_ba - U_stable_B
    print(f"\nBarrier Height A -> B: {barrier_height_ab:.4f}")
    print(f"Barrier Height B -> A: {barrier_height_ba:.4f}")
    
    if visualize:
        visualize_landscape(U, X_grid, Y_grid, projected_ss, saddle_coords_ab, proj_path_ab, saddle_coords_ba, proj_path_ba)
    
    results_dict = {
        "actions": {"A_to_B": action_a_to_b, "B_to_A": action_b_to_a},
        "barrier_heights": {"A_to_B": barrier_height_ab, "B_to_A": barrier_height_ba}
    }
    
    return results_dict


if __name__ == '__main__':
    try:
        # Example for a 4-node network
        adj_matrix=[[0,1,-1,-1], [1,0,-1,-1], [-1,-1,0,1], [-1,-1,1,0]]
        adj_matrix=[[1,-1],[-1,1]]
        TOPOLOGY_FILE_4NODE = 'four_node_team.txt'
        if not os.path.exists(TOPOLOGY_FILE_4NODE):
             np.savetxt(TOPOLOGY_FILE_4NODE, adj_matrix, fmt='%d', header='Source Target Type', comments='')

        param_id_to_test = 666

        # --- START OF MODIFICATION 5: Call the analysis with a non-zero lambda ---
        results = run_drl_analysis(
            network_name="MISA", 
            adjacency_matrix=adj_matrix, 
            param_id=param_id_to_test, 
            d_coefficient=0.1, 
            visualize=True,
            regularization_lambda=0.9 # Set a small value to enable smoothness penalty
        )
        
        if results:
            print("\n\n" + "="*25 + " FINAL RESULTS " + "="*25)
            print(results)
            
    except Exception as e:
        import traceback
        traceback.print_exc()